{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51yk78Fb3eu2"
      },
      "source": [
        "# Model Evaluation\n",
        "\n",
        "In this notebook, we will evaluate our fine-tuned text simplification model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "657Qw74k2yAL"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "save_path = r\"E:\\simplification_model\"\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(save_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WqfS0Up8LfI"
      },
      "source": [
        "## Generate Predictions on Validation Set\n",
        "We take a sample of the validation data, pass it through the model,  \n",
        "and decode the generated output into human-readable text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEptn58CnZza"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def generate_predictions(dataset, num_samples=20):\n",
        "    examples = dataset.shuffle(seed=42).select(range(num_samples))\n",
        "    inputs_text = examples['source_text']\n",
        "    targets_text = examples['target_text']\n",
        "\n",
        "    preds = []\n",
        "    for text in inputs_text:\n",
        "        inputs_enc = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "        inputs_enc = {k:v.to(device) for k,v in inputs_enc.items()}\n",
        "        outputs = model.generate(**inputs_enc, max_length=128, num_beams=4)\n",
        "        decoded = tokenizer.decode(outputs[0].cpu(), skip_special_tokens=True)\n",
        "        preds.append(decoded)\n",
        "\n",
        "    return inputs_text, preds, targets_text\n",
        "\n",
        "inputs, preds, targets = generate_predictions(val_dataset, num_samples=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIJYdhycEdgW"
      },
      "source": [
        "# Evaluate with Metrics (BLEU, ROUGE)\n",
        "These metrics compare generated predictions with the reference target text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCA9384cEcKt"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in e:\\t5env\\lib\\site-packages (0.4.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in e:\\t5env\\lib\\site-packages (from evaluate) (4.0.0)\n",
            "... [dependency installation output truncated for brevity] ...\n",
            "Successfully installed absl-py-2.3.1 click-8.2.1 nltk-3.9.1 rouge_score-0.1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  DEPRECATION: Building 'rouge_score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge_score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: {'bleu': 0.536825251888985, 'precisions': [0.672093023255814, 0.5560975609756098, 0.49230769230769234, 0.45135135135135135], 'brevity_penalty': 1.0, 'length_ratio': 1.2078651685393258, 'translation_length': 430, 'reference_length': 356}\n",
            "ROUGE Score: {'rouge1': 0.7305138188820598, 'rouge2': 0.6054983573466652, 'rougeL': 0.7025116620416674, 'rougeLsum': 0.7031786447654161}\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate\n",
        "!pip install nltk absl-py rouge_score\n",
        "\n",
        "import evaluate\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "filtered_data = [(i, p, t) for i, p, t in zip(inputs, preds, targets) if t is not None]\n",
        "inputs_filtered, preds_filtered, targets_filtered = zip(*filtered_data) if filtered_data else ([], [], [])\n",
        "\n",
        "bleu_score = bleu.compute(predictions=list(preds_filtered), references=[[t] for t in targets_filtered])\n",
        "rouge_score = rouge.compute(predictions=list(preds_filtered), references=list(targets_filtered))\n",
        "\n",
        "print(\"BLEU Score:\", bleu_score)\n",
        "print(\"ROUGE Score:\", rouge_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation Insights\n",
        "\n",
        "- **BLEU Score:** 0.54 → Indicates good overlap between model predictions and reference simplifications; much better than typical scores (0.2–0.4) for text generation tasks.  \n",
        "- **ROUGE Scores:**  \n",
        "  - ROUGE-1: 0.73  \n",
        "  - ROUGE-2: 0.61  \n",
        "  - ROUGE-L: 0.70  \n",
        "  These high scores show the model preserves key words, phrases, and sentence structure effectively.  \n",
        "\n",
        "**Conclusion:** The model performs well on simplification, producing outputs that are close to human references in both content and readability."
      ],
      "metadata": {
        "id": "TDXeR5vvdvdL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo"
      ],
      "metadata": {
        "id": "X0xx9yOqnqQT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsNZxLJrIP9n"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to simplify (or type 'quit' to exit):\n",
            "Original: the yowa era, marked by famine, ends in japan.\n",
            "Simplified: the yowa era ends in japan.\n",
            "------\n",
            "Original: She now has an album and a huge hit single, which topped the charts and attracted millions of views.\n",
            "Simplified: she now has an album and a huge hit single.\n",
            "------\n",
            "Original: it was here that he composed messiah, zadok the priest and music for the royal fireworks.\n",
            "Simplified: he composed messiah, zadok the priest and music for the royal fireworks.\n",
            "------\n",
            "Original: the slide rule, also known colloquially as a slipstick, is a mechanical analog computer.\n",
            "Simplified: the slide rule, also known as a slipstick, is a mechanical analog computer.\n",
            "------\n",
            "Original: quit\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "model_path = r\"E:\\simplification_model\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def simplify_text(sentence):\n",
        "    inputs_enc = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "    outputs = model.generate(\n",
        "        inputs_enc['input_ids'],\n",
        "        max_length=60,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Enter a sentence to simplify (or type 'quit' to exit):\")\n",
        "while True:\n",
        "    text = input()\n",
        "    if text.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "        print(f\"Original: {text}\")\n",
        "        break\n",
        "    simplified = simplify_text(text)\n",
        "    print(f\"Original: {text}\")\n",
        "    print(f\"Simplified: {simplified}\")\n",
        "    print(\"------\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (T5Env)",
      "language": "python",
      "name": "t5env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}