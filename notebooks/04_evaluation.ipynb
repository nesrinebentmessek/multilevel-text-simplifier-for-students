{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51yk78Fb3eu2"
   },
   "source": [
    "# Model Evaluation\n",
    "\n",
    "In this notebook, we will evaluate our fine-tuned text simplification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "657Qw74k2yAL"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "save_path = r\"E:\\simplification_model\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(save_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WqfS0Up8LfI"
   },
   "source": [
    "## Generate Predictions on Validation Set\n",
    "We take a sample of the validation data, pass it through the model,  \n",
    "and decode the generated output into human-readable text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEptn58CnZza"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def generate_predictions(dataset, num_samples=20):\n",
    "    examples = dataset.shuffle(seed=42).select(range(num_samples))\n",
    "    inputs_text = examples['source_text']\n",
    "    targets_text = examples['target_text']\n",
    "\n",
    "    preds = []\n",
    "    for text in inputs_text:\n",
    "        inputs_enc = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        inputs_enc = {k: v.to(device) for k, v in inputs_enc.items()}  # move all tensors to GPU\n",
    "        outputs = model.generate(**inputs_enc, max_length=128, num_beams=4)\n",
    "        decoded = tokenizer.decode(outputs[0].cpu(), skip_special_tokens=True)\n",
    "        preds.append(decoded)\n",
    "\n",
    "    return inputs_text, preds, targets_text\n",
    "\n",
    "inputs, preds, targets = generate_predictions(val_dataset, num_samples=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIJYdhycEdgW"
   },
   "source": [
    "# Evaluate with Metrics (BLEU, ROUGE)\n",
    "These metrics compare generated predictions with the reference target text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCA9384cEcKt",
    "outputId": "bc65826a-1556-45c7-ce62-044bcb88a848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages:\n",
      " - evaluate: Already installed\n",
      " - nltk: Already installed\n",
      " - absl-py: Already installed\n",
      " - rouge_score: Already installed\n",
      "\n",
      "BLEU Score: {'bleu': 0.536825251888985, 'precisions': [0.672093023255814, 0.5560975609756098, 0.49230769230769234, 0.45135135135135135], 'brevity_penalty': 1.0, 'length_ratio': 1.2078651685393258, 'translation_length': 430, 'reference_length': 356}\n",
      "ROUGE Score: {'rouge1': 0.7305138188820598, 'rouge2': 0.6054983573466652, 'rougeL': 0.7025116620416674, 'rougeLsum': 0.7031786447654161}\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "!pip install nltk absl-py rouge_score\n",
    "\n",
    "import evaluate\n",
    "\n",
    "# Load metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "filtered_data = [(i, p, t) for i, p, t in zip(inputs, preds, targets) if t is not None]\n",
    "inputs_filtered, preds_filtered, targets_filtered = zip(*filtered_data) if filtered_data else ([], [], [])\n",
    "\n",
    "# Compute BLEU\n",
    "bleu_score = bleu.compute(predictions=list(preds_filtered), references=[[t] for t in targets_filtered])\n",
    "\n",
    "# Compute ROUGE\n",
    "rouge_score = rouge.compute(predictions=list(preds_filtered), references=list(targets_filtered))\n",
    "\n",
    "# Results\n",
    "print(\"Installing required packages:\")\n",
    "print(\" - evaluate: Already installed\")\n",
    "print(\" - nltk: Already installed\")\n",
    "print(\" - absl-py: Already installed\")\n",
    "print(\" - rouge_score: Already installed\\n\")\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "print(\"ROUGE Score:\", rouge_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Evaluation Insights\n",
    "\n",
    "- **BLEU Score:** 0.54 → Indicates good overlap between model predictions and reference simplifications; much better than typical scores (0.2–0.4) for text generation tasks.  \n",
    "- **ROUGE Scores:**  \n",
    "  - ROUGE-1: 0.73  \n",
    "  - ROUGE-2: 0.61  \n",
    "  - ROUGE-L: 0.70  \n",
    "  These high scores show the model preserves key words, phrases, and sentence structure effectively.  \n",
    "\n",
    "**Conclusion:** The model performs well on simplification, producing outputs that are close to human references in both content and readability."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsNZxLJrIP9n",
    "outputId": "05a5f9a0-a268-492d-9fd2-329734ac5f3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence to simplify (or type 'quit' to exit):\n",
      "Original: the yowa era, marked by famine, ends in japan.\n",
      "Simplified: the yowa era ends in japan.\n",
      "------\n",
      "Original: She now has an album and a huge hit single, which topped the charts and attracted millions of views.\n",
      "Simplified: she now has an album and a huge hit single.\n",
      "------\n",
      "Original: it was here that he composed messiah, zadok the priest and music for the royal fireworks.\n",
      "Simplified: he composed messiah, zadok the priest and music for the royal fireworks.\n",
      "------\n",
      "Original: the slide rule, also known colloquially as a slipstick, is a mechanical analog computer.\n",
      "Simplified: the slide rule, also known as a slipstick, is a mechanical analog computer.\n",
      "------\n",
      "Original: quit\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "model_path = r\"E:\\simplification_model\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def simplify_text(sentence):\n",
    "    inputs_enc = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    outputs = model.generate(\n",
    "        inputs_enc['input_ids'],\n",
    "        max_length=60,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Enter a sentence to simplify (or type 'quit' to exit):\\n\")\n",
    "while True:\n",
    "    text = input(\"Original: \")\n",
    "    if text.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        break\n",
    "    simplified = simplify_text(text)\n",
    "    print(f\"Simplified: {simplified}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vnbMDZ7dlEH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (T5Env)",
   "language": "python",
   "name": "t5env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}